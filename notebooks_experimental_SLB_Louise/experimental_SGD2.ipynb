{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "import copy\n",
    "from simu_PSF_polar import *\n",
    "from extract_experimental_psf import *\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using GPU\")\n",
    "else:   \n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255276e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([1.1643099, 1.4462458, 1.7931267])+1.1\n",
    "#d = np.array([np.mean(d)-0.350, np.mean(d), np.mean(d)+0.350])\n",
    "QE = 0.92\n",
    "EM = 250\n",
    "sensitivity = 15.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10271552",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nframe=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c170c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = np.zeros((Nframe,6,214,129))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a807dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_info = '\\\\\\\\NAS_LOCCO\\\\Amaury\\\\PolMFM_SilicaBeads_SLB_NR\\\\image_Pos0_2.ome_results_fr1to8095_method=Propagation matrix_box-method=Fixed_invertRotationPolarizer_corr.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee60ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(frame_0, N_frame):\n",
    "    error_indices = []\n",
    "    for i in range(N_frame):\n",
    "        number = str(frame_0 + i).zfill(4)\n",
    "        print(number)\n",
    "        path_data = '\\\\\\\\NAS_LOCCO\\\\Amaury\\\\PolMFM_SilicaBeads_SLB_NR\\\\2024-01-11_SilicaBeads_Lipids_NR\\\\001_SM_560nm_EM250_25ms\\\\SilicaBead\\\\images\\\\RAW_DATA\\\\image_Pos0_2_reco\\\\image_Pos0_2_'+number+'.tif'\n",
    "        raw_ = extract_raw(path_data)\n",
    "        if raw_ is None:\n",
    "            error_indices.append(i)\n",
    "            continue\n",
    "        else:\n",
    "            raw[i] = raw_\n",
    "        del(raw_)\n",
    "    return raw, error_indices\n",
    "\n",
    "def extract_positions(frame_0, N_frame, error_indices):\n",
    "    index_frame = []\n",
    "    x, y, z, rho, delta = [], [], [], [], []\n",
    "    ind = 0\n",
    "    for i in range(N_frame):\n",
    "        if i not in error_indices:\n",
    "            x__, y__, z__, rho__, delta__ = position_from_data(data, frame_0+i)\n",
    "            x = np.concatenate((x, x__))\n",
    "            y = np.concatenate((y, y__))\n",
    "            z = np.concatenate((z, z__))\n",
    "            rho = np.concatenate((rho, rho__))\n",
    "            delta = np.concatenate((delta, delta__))\n",
    "            for k in range(len(x__)):\n",
    "                index_frame.append(ind)\n",
    "        ind+=1\n",
    "    index_frame=np.array(index_frame)\n",
    "    return x, y, z, rho, delta, index_frame\n",
    "\n",
    "def limit(x, lim, slope, upper=True):\n",
    "    '''\n",
    "    if upper:\n",
    "       return torch.sum(torch.tensor(1/(1+torch.exp(-slope*(x-lim))), requires_grad=True, device=device))\n",
    "    else:\n",
    "        return torch.sum(torch.tensor(1/(1+torch.exp(slope*(x-lim))), requires_grad=True, device=device))\n",
    "    '''\n",
    "    if upper:\n",
    "        return torch.sum(torch.exp((x-lim)*slope))\n",
    "    else:\n",
    "        return torch.sum(torch.exp(-1*(x-lim)*slope))\n",
    "    \n",
    "def loss_pos(xp, yp, zp, rho, eta, delta, N_photons, data, second_plane, offset_planes, background, sigma, dim_simu):\n",
    "    u, v, M_ = compute_M(xp=xp, yp=yp, zp=zp, d=d_, x=xx, y=yy, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k_, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections, N=N,\n",
    "                    l_pixel=l_pixel, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG, device=device, aberrations=False, planes_offset=offset_planes*torch.tensor([0,0,0], device=device))\n",
    "    dim_data = 6\n",
    "    h = PSF(rho=rho, eta=eta, delta=delta, M=M_, N_photons=N_photons)[:,:,:,dim_simu-dim_data:dim_simu+dim_data+1,dim_simu-dim_data:dim_simu+dim_data+1]\n",
    "    loss = torch.sum(torch.add(h, -(data+sigma**2)*torch.log(h+background+sigma**2)))\n",
    "    #loss = torch.sum(torch.pow(torch.sum(torch.add(h, -data), dim=(2,)), 2)) \n",
    "    x_bound = limit(xp, 5*0.12, 100, upper=True) + limit(xp, -5*0.12, 100, upper=False)\n",
    "    y_bound = limit(yp, 5*0.12, 100, upper=True) + limit(yp, -5*0.12, 100, upper=False)\n",
    "    z_bound = limit(zp, 5., 100, upper=True) + limit(zp, 0, 100, upper=False)\n",
    "    N_bound = limit(N_photons, 10000., 0.01, upper=True)\n",
    "    return loss +x_bound+y_bound+z_bound#+N_bound\n",
    "\n",
    "def loss_angle(M_, rho, eta, delta, N_photons, data, background, sigma, dim_simu):\n",
    "    dim_data = 6\n",
    "    h = PSF(rho=rho, eta=eta, delta=delta, M=M_, N_photons=N_photons)[:,:,:,dim_simu-dim_data:dim_simu+dim_data+1,dim_simu-dim_data:dim_simu+dim_data+1]\n",
    "\n",
    "    loss = torch.sum(torch.add(h, -(data+sigma**2)*torch.log(h+background+sigma**2)))\n",
    "    #loss = torch.sum(torch.pow(torch.sum(torch.add(h, -data), dim=(2,)), 2)) \n",
    "    delta_bound = limit(delta, 180, 100, upper=True) + limit(delta, 1, 100, upper=False)\n",
    "    N_bound = limit(N_photons, 10000., 0.01, upper=True)\n",
    "    return loss + 1000.*(delta_bound)# + N_bound) #+ 100000*torch.sum(h**2)\n",
    "\n",
    "def loss_angle_with_M(polar_proj, x_, y_, z_, rho, eta, delta, N_photons, data, background, sigma, dim_simu, offset_planes):\n",
    "    dim_data = 6\n",
    "    u, v, M_ = compute_M(xp=x_, yp=y_, zp=z_, d=d_, x=xx, y=yy, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k_, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections, N=N, l_pixel=l_pixel\n",
    "                    , NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG, device=device, polar_offset=polar_proj, planes_offset=offset_planes)\n",
    "    h = PSF(rho=rho, eta=eta, delta=delta, M=M_, N_photons=N_photons)[:,:,:,dim_simu-dim_data:dim_simu+dim_data+1,dim_simu-dim_data:dim_simu+dim_data+1]\n",
    "    \n",
    "    loss = torch.sum(torch.add(h, -(data+sigma**2)*torch.log(h+background+sigma**2)))\n",
    "    #loss = torch.sum(torch.pow(torch.sum(torch.add(h, -data), dim=(2,)), 2)) \n",
    "    delta_bound = limit(delta, 180, 100, upper=True) + limit(delta, 1, 100, upper=False)\n",
    "    N_bound = limit(N_photons, 10000., 0.01, upper=True)\n",
    "    return loss + 1000.*(delta_bound)# + N_bound) #+ 100000*torch.sum(h**2)\n",
    "\n",
    "def score_eval(M_, rho, eta, delta, N_photons, data, background, sigma, dim_simu):\n",
    "    dim_data = 6\n",
    "    h = PSF(rho=rho, eta=eta, delta=delta, M=M_, N_photons=N_photons)[:,:,:,dim_simu-dim_data:dim_simu+dim_data+1,dim_simu-dim_data:dim_simu+dim_data+1]\n",
    "    score = torch.sum(torch.add(h, -(data+sigma**2)*torch.log(h+background+sigma**2)), dim=(1,2,3,4))\n",
    "    return score.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pos_from_csv(path_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aef058",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_batch = 350 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027cdfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_analytical(value, b1, s1, b2, s2):\n",
    "    num_points=2000\n",
    "    t = torch.linspace(0, 1, num_points).unsqueeze(0)  # shape: (1, 100)\n",
    "    cst = torch.tensor([1. for fgh in range(num_points)])\n",
    "    \n",
    "    r_range = (value.unsqueeze(1) * t)\n",
    "    l_range = (5*value.unsqueeze(1) * t)\n",
    "    dr_range = ((value/num_points).unsqueeze(1) * cst)\n",
    "    dl_range = ((5*value/num_points).unsqueeze(1) * cst)\n",
    "    \n",
    "    rr = r_range.unsqueeze(2).expand(-1, num_points, num_points)\n",
    "    ll = l_range.unsqueeze(1).expand(-1, num_points, num_points)\n",
    "    dr = dr_range.unsqueeze(2).expand(-1, num_points, num_points)\n",
    "    dl = dl_range.unsqueeze(1).expand(-1, num_points, num_points)    \n",
    "\n",
    "    return (1/(2*torch.pi*s1*s2))*torch.sum(((ll**(value.view(-1, 1, 1)-rr))/(torch.exp(torch.lgamma(1+value.view(-1, 1, 1)-rr))))*dr*dl*torch.exp(-ll -0.5*((ll-b1)/s1)**2 -0.5*((rr-b2)/s2)**2), dim=(1,2))\n",
    "\n",
    "def distrib_approx(data):\n",
    "    NN = len(data)\n",
    "    histo = plt.hist(data, bins=int(NN/20000))\n",
    "    plt.show()\n",
    "    dhisto = histo[1][1]-histo[1][0]\n",
    "    x = histo[1]+dhisto/2\n",
    "    y = histo[0]\n",
    "    y = y/np.sum(y)\n",
    "    uu = y/dhisto\n",
    "    del(histo)\n",
    "    return x[:-1], uu\n",
    "\n",
    "raw, error_indices = extract_frames(1, 10)\n",
    "x, y, z, rho, delta, index_frame = extract_positions(1, 10, error_indices)\n",
    "raw = raw*sensitivity/(QE*EM)\n",
    "\n",
    "abscisse, distrib_exp = distrib_approx(raw.flatten())\n",
    "absc = torch.tensor(abscisse)\n",
    "res = noise_analytical(absc, 10.5, 6.8, 11, 1.)\n",
    "del(abscisse, distrib_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d48b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_count = 14.1\n",
    "print(offset_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_number in range(N_batch):\n",
    "    t0 = time.time()\n",
    "    raw, error_indices = extract_frames((batch_number+batch_offset)*Nframe+1, Nframe)\n",
    "    x, y, z, rho, delta, index_frame = extract_positions((batch_number+batch_offset)*Nframe+1, Nframe, error_indices)\n",
    "    raw = raw*sensitivity/(QE*EM)\n",
    "    hist = plt.hist(raw.flatten(), bins=100)\n",
    "    plt.show()\n",
    "    del(hist)\n",
    "    raw = raw+offset_count\n",
    "    pdf = res[:torch.argmin((absc-offset_count-0.3)**2)].detach().numpy()\n",
    "    pdf=pdf/np.sum(pdf)\n",
    "    for ini in range(raw.shape[0]):\n",
    "        for iii in range(raw.shape[1]):\n",
    "            for jjj in range(raw.shape[2]):\n",
    "                for kkk in range(raw.shape[3]):\n",
    "                    if raw[ini,iii,jjj,kkk]<offset_count+0.5:\n",
    "                        raw[ini,iii,jjj,kkk] = np.random.choice(np.linspace(0,offset_count+0.5,len(pdf)), p=pdf)\n",
    "    hist = plt.hist(raw.flatten(), bins=100)\n",
    "    plt.show()\n",
    "    del(hist)\n",
    "    sigma = np.std(raw.flatten())\n",
    "    background = np.mean(raw.flatten())\n",
    "\n",
    "    nb = len(x)\n",
    "    for k, ele in enumerate(x):\n",
    "        if np.isnan(x[nb-1-k]) or np.isnan(y[nb-1-k]) or np.isnan(z[nb-1-k]) or np.isnan(rho[nb-1-k]) or np.isnan(delta[nb-1-k]):\n",
    "            x = np.delete(x,nb-1-k,0)\n",
    "            y = np.delete(y,nb-1-k,0)\n",
    "            z = np.delete(z,nb-1-k,0)\n",
    "            rho = np.delete(rho,nb-1-k,0)\n",
    "            delta = np.delete(delta,nb-1-k,0)\n",
    "            index_frame = np.delete(index_frame,nb-1-k,0)\n",
    "    \n",
    "    NPSF = len(x)\n",
    "\n",
    "    single_psf = extract_raw_xy(raw[0], x[index_frame==0], y[index_frame==0])\n",
    "    for i in range(1,Nframe):\n",
    "        single_psf = np.concatenate((single_psf, extract_raw_xy(raw[i], x[index_frame==i], y[index_frame==i])))\n",
    "\n",
    "    single_psf = single_psf[:,::-1]\n",
    "\n",
    "    x_start = torch.tensor([0. for k in range(len(x))], requires_grad=False, device=device)\n",
    "    y_start = torch.tensor([0. for k in range(len(x))], requires_grad=False, device=device)\n",
    "\n",
    "    z_exp =  torch.tensor([1.2 for k in range(len(x))], requires_grad=False, device=device) \n",
    "\n",
    "    rho_exp = torch.tensor(rho, requires_grad=False, device=device)\n",
    "    delta_exp = torch.tensor(delta, requires_grad=False, device=device)\n",
    "\n",
    "    d_ = -torch.tensor([d[1] for k in range(len(x))], requires_grad=False, device=device)\n",
    "    second_plane = torch.tensor([d[1]-d[0], 0, d[1]-d[2]], device=device)\n",
    "    polar_projections = torch.tensor(np.array([0, 45, 0]), device=device)\n",
    "\n",
    "    N=torch.tensor(80, device=device)\n",
    "    l_pixel=torch.tensor(16, device=device)\n",
    "    NA=torch.tensor(1.4, device=device)\n",
    "    mag=torch.tensor(100, device=device)\n",
    "    lambd=torch.tensor(638, device=device)\n",
    "    f_tube=torch.tensor(200, device=device)\n",
    "    MAG=torch.tensor(200/150, device=device)\n",
    "\n",
    "    xx, yy, th1, phi, [Ex0, Ex1, Ex2], [Ey0, Ey1, Ey2], r, r_cut, k_, f_o = vectorial_BFP_perfect_focus(N, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, device=device)\n",
    "\n",
    "    noisy_psf = torch.tensor([single_psf[k] for k in range(len(x))], device=device)\n",
    "\n",
    "    u, v, M = compute_M(xp=x_start, yp=y_start, zp=z_exp, d=d_, x=xx, y=yy, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k_, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections, N=N, l_pixel=l_pixel\n",
    "                    , NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG, device=device)\n",
    "    h = PSF(rho=torch.tensor(np.array([45. for k in range(NPSF)]), device=device), eta=torch.tensor([45. for k in range(NPSF)], device=device), delta=torch.tensor([100. for k in range(NPSF)], device=device), M=M, N_photons=torch.tensor([1000. for k in range(NPSF)], device=device))\n",
    "    \n",
    "    dim_simu = int(h.shape[-1]//2)\n",
    "\n",
    "    ### first SGD on pos\n",
    "    Nstart = torch.tensor([3000 for i in range(NPSF)], requires_grad=False, device=device)\n",
    "    eta_rd = torch.tensor([45. for k in range(NPSF)], requires_grad=False, device=device)\n",
    "    delta_rd = torch.tensor([150. for k in range(NPSF)], requires_grad=False, device=device)\n",
    "    shift=torch.zeros(3, device=device)\n",
    "    params = torch.cat((x_start, y_start, z_exp, Nstart/1000, shift))\n",
    "    params.requires_grad=True\n",
    "    optimizer = torch.optim.Adam([params], lr=0.15)\n",
    "    #params = torch.cat((x_start, y_start, z_exp, Nstart/1000, shift))\n",
    "\n",
    "    optimizer = torch.optim.Adam([params], lr=0.15)  # Learning rate = 0.012\n",
    "\n",
    "    num_epochs_max = 100\n",
    "    loss_ = []\n",
    "    dd = []\n",
    "    for i in tqdm(range(num_epochs_max)):\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        loss = loss_pos(params[0:NPSF], params[NPSF:2*NPSF], params[2*NPSF:3*NPSF], rho_exp\n",
    "                            , eta_rd, delta_exp, params[3*NPSF:4*NPSF]*1000, noisy_psf, second_plane, params[-3:], background, sigma, dim_simu) \n",
    "        loss_.append(loss.cpu().detach().numpy())\n",
    "        dd.append(params[-3:].cpu().detach().numpy())\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update parameters\n",
    "    ax = plt.plot(loss_)\n",
    "    plt.ylim((np.min(np.array(loss_)), np.max(np.array(loss_))))\n",
    "    plt.show()\n",
    "    del(ax, loss_)\n",
    "    ax = plt.plot(dd)\n",
    "    plt.show()\n",
    "    del(ax)\n",
    "\n",
    "    x_found = params[0:NPSF].detach()\n",
    "    y_found = params[NPSF:2*NPSF].detach()\n",
    "    z_found = params[2*NPSF:3*NPSF].detach()\n",
    "    N_found = params[3*NPSF:4*NPSF].detach()*1000\n",
    "    offset_planes_found = params[-3:].detach()\n",
    "    del(params, loss)\n",
    "    print('NPSF = ', NPSF)\n",
    "\n",
    "    ### SGD 2 on orientation\n",
    "    offset_proj=20.\n",
    "    u, v, M_i = compute_M(xp=x_found, yp=y_found, zp=z_found, d=d_, x=xx, y=yy, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k_, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections+offset_proj, N=N, l_pixel=l_pixel\n",
    "                    , NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG, device=device)\n",
    "    \n",
    "    eta_rd = torch.tensor([90. for k in range(NPSF)], requires_grad=False, device=device)\n",
    "    \n",
    "    #params = torch.cat((rho_exp, eta_rd, delta_exp, N_found/1000))\n",
    "    params = torch.cat((eta_rd, eta_rd, eta_rd, N_found/1000, x_found*15, y_found*15, torch.tensor([offset_proj/2], requires_grad=False, device=device)))\n",
    "    #params = torch.cat((eta_rd, eta_rd, eta_rd, N_found/1000, torch.tensor([offset_proj], requires_grad=False, device=device)))\n",
    "    params.requires_grad=True\n",
    "\n",
    "    # Use Stochastic Gradient Descent (SGD) to optimize params\n",
    "    optimizer = torch.optim.Adam([params], lr=0.7)  # Learning rate = 0.01\n",
    "\n",
    "    num_epochs_max = 300\n",
    "    loss_ = []\n",
    "    eta_ = []\n",
    "    #pol=[]\n",
    "    for i in tqdm(range(num_epochs_max)):\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        #loss = loss_angle(M.detach(), params[:NPSF], params[1*NPSF:2*NPSF], params[2*NPSF:3*NPSF], 1000*params[3*NPSF:4*NPSF], noisy_psf, background, sigma, dim_simu)\n",
    "        if i<90:\n",
    "            loss = loss_angle_with_M(offset_proj, params[4*NPSF:5*NPSF]/15, params[5*NPSF:6*NPSF]/15, z_found, params[:NPSF], params[1*NPSF:2*NPSF], params[2*NPSF:3*NPSF], 1000*params[3*NPSF:4*NPSF], noisy_psf, background, sigma, dim_simu, offset_planes_found)\n",
    "        else:\n",
    "            loss = loss_angle_with_M(params[-1]*2, params[4*NPSF:5*NPSF]/15, params[5*NPSF:6*NPSF]/15, z_found, params[:NPSF], params[1*NPSF:2*NPSF], params[2*NPSF:3*NPSF], 1000*params[3*NPSF:4*NPSF], noisy_psf, background, sigma, dim_simu, offset_planes_found)\n",
    "        loss_.append(loss.cpu().detach().numpy())\n",
    "        #eta_.append(params[1*NPSF:2*NPSF].cpu().detach().numpy())\n",
    "        eta_.append(params[-1].cpu().detach().numpy()*2)\n",
    "        #pol.append(params[-1].cpu().detach().numpy())\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update parameters\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].plot(loss_) \n",
    "    #ax[0].set_ylim((np.min(np.array(loss_)), np.max(np.array(loss_))))\n",
    "    ax[1].plot(eta_)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    del(fig, ax)\n",
    "\n",
    "    rho_found=params[0:NPSF].detach()%180\n",
    "    eta_found=params[1*NPSF:2*NPSF].detach()%180\n",
    "    delta_found=params[2*NPSF:3*NPSF].detach()\n",
    "    x_found2 = params[4*NPSF:5*NPSF].detach()/15\n",
    "    y_found2 = params[5*NPSF:6*NPSF].detach()/15\n",
    "    z_found2 = z_found #params[6*NPSF:7*NPSF].detach()/15\n",
    "    N_found2 = 1000*params[3*NPSF:4*NPSF].detach()\n",
    "    offset_proj_found = params[-1].detach()*2\n",
    "    del(params, loss, eta_, loss_)\n",
    "\n",
    "    u, v, M_end = compute_M(xp=x_found2, yp=y_found2, zp=z_found2, d=d_, x=xx, y=yy, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k_, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections+offset_proj_found.cpu(), N=N, l_pixel=l_pixel\n",
    "                    , NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG, device=device, polar_offset=offset_proj_found, planes_offset=offset_planes_found)\n",
    "    score = score_eval(M_end.detach().cpu(), rho_found.cpu(), eta_found.cpu(), delta_found.cpu(), N_found2.cpu(), noisy_psf.cpu(), background, sigma, dim_simu)\n",
    "    x_ = (x/0.120).astype(int)*0.12 + x_found2.cpu().detach().numpy()\n",
    "    y_ = (y/0.120).astype(int)*0.12 + y_found2.cpu().detach().numpy()\n",
    "    np.savez_compressed('D:/AMAURY/experimental_processed/stage/NAME/'+str(int(batch_number)+1+batch_offset)+'.npz', frame = index_frame, x=x_, y=y_, z=1000*z_found2.cpu().detach().numpy(), N_photons=N_found2.cpu().detach().numpy(), offset_proj=offset_proj_found.cpu().detach().numpy(), offset_planes=offset_planes_found.cpu().detach().numpy(), rho=rho_found.cpu().detach().numpy(), eta=eta_found.cpu().detach().numpy(), delta=delta_found.cpu().detach().numpy(), score=score, x_start=x, y_start=y, z_start=z, rho_start=rho, delta_start=delta)\n",
    "    \n",
    "    best = np.argmin(score)\n",
    "    dim_data = 6\n",
    "\n",
    "    h = PSF(rho=rho_found, eta=eta_found, delta=delta_found, M=M_end, N_photons=N_found2)[:,:,:,dim_simu-dim_data:dim_simu+dim_data+1,dim_simu-dim_data:dim_simu+dim_data+1]\n",
    "    for uuu in range(h.shape[0]):\n",
    "        vmin = 0.\n",
    "        vmax = np.max(noisy_psf.cpu().detach().numpy()[uuu])\n",
    "        fig, ax = plt.subplots(2,3)\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                ax[i,j].set_aspect('equal')\n",
    "                im = ax[i,j].pcolormesh(noisy_psf.cpu().detach().numpy()[uuu,j,i], cmap='grey', vmin=vmin, vmax=vmax)\n",
    "                ax[i,j].set_title(str(np.sum(noisy_psf.cpu().detach().numpy()[uuu,j,i])))\n",
    "        fig.colorbar(im, ax=ax.ravel().tolist(), shrink=0.8)\n",
    "        plt.show()\n",
    "        del(fig, ax)\n",
    "        vmin = 0.\n",
    "        vmax = np.max(h.cpu().detach().numpy()[uuu])\n",
    "        fig, ax = plt.subplots(2,3)\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                ax[i,j].set_aspect('equal')\n",
    "                im = ax[i,j].pcolormesh(h.cpu().detach().numpy()[uuu,j,i], cmap='grey', vmin=vmin, vmax=vmax)\n",
    "                ax[i,j].set_title(str(np.sum(h.cpu().detach().numpy()[uuu,j,i])))\n",
    "        fig.colorbar(im, ax=ax.ravel().tolist(), shrink=0.8)\n",
    "        plt.show()\n",
    "        del(fig, ax)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fea8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
