{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simu_PSF_polar import *\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [5,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using GPU\")\n",
    "else:   \n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit(x, lim, slope, upper=True):\n",
    "    '''\n",
    "    if upper:\n",
    "       return torch.sum(torch.tensor(1/(1+torch.exp(-slope*(x-lim))), requires_grad=True, device=device))\n",
    "    else:\n",
    "        return torch.sum(torch.tensor(1/(1+torch.exp(slope*(x-lim))), requires_grad=True, device=device))\n",
    "    '''\n",
    "    if upper:\n",
    "        return torch.sum(torch.exp((x-lim)*slope))\n",
    "    else:\n",
    "        return torch.sum(torch.exp(-1*(x-lim)*slope))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_photons= torch.tensor(5000., device=device)\n",
    "N=torch.tensor(80, device=device)\n",
    "l_pixel=torch.tensor(16, device=device)\n",
    "NA=torch.tensor(1.4, device=device)\n",
    "mag=torch.tensor(100, device=device)\n",
    "lambd=torch.tensor(617, device=device)\n",
    "f_tube=torch.tensor(200, device=device)\n",
    "MAG=torch.tensor(200/150, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = torch.tensor(0.3*(2*np.random.rand(100)-1), device=device)\n",
    "yp = torch.tensor(0.3*(2*np.random.rand(100)-1), device=device)\n",
    "z = torch.tensor((1.+np.random.rand(100))*0.8, device=device) #position of dipole in lambda units\n",
    "d_ = torch.tensor([-1.5 for k in range(100)], device=device) #defocus of dipole in lambda units 4.4\n",
    "rho = torch.tensor(10.+160.*np.random.rand(100), requires_grad=True, device=device)\n",
    "eta = torch.tensor(30.+150.*np.random.rand(100), requires_grad=True, device=device)# 70\n",
    "delta = torch.tensor(70.+80.*np.random.rand(100), requires_grad=True, device=device)#50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, th1, phi, [Ex0, Ex1, Ex2], [Ey0, Ey1, Ey2], r, r_cut, k_, f_o = vectorial_BFP_perfect_focus(N, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_plane = torch.tensor([0.35, 0, -0.35], device=device)\n",
    "polar_projections = torch.tensor([0., 45., 0.], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v, M = compute_M(xp=xp, yp=yp, zp=z, d=d_, x=x, y=y, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k_, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections, N=N, l_pixel=l_pixel, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG,\n",
    "                   device=device, aberrations=False, defocus_coef=1e-5, spherical_coef=-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = PSF(rho=rho, eta=eta, delta=delta, M=M, N_photons=N_photons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 12\n",
    "print('z = ', z[nn].cpu().detach().numpy())\n",
    "\n",
    "vmax=torch.max(psf[nn]).cpu().detach().numpy()\n",
    "vmin=torch.min(psf[nn]).cpu().detach().numpy()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15,9]\n",
    "fig, ax = plt.subplots(2,3)\n",
    "mesh1 = ax[0,0].pcolormesh(u.cpu(), v.cpu(), psf[nn,0,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh2 = ax[1,0].pcolormesh(u.cpu(), v.cpu(), psf[nn,0,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh3 = ax[0,1].pcolormesh(u.cpu(), v.cpu(), psf[nn,1,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh4 = ax[1,1].pcolormesh(u.cpu(), v.cpu(), psf[nn,1,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh5 = ax[0,2].pcolormesh(u.cpu(), v.cpu(), psf[nn,2,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh6 = ax[1,2].pcolormesh(u.cpu(), v.cpu(), psf[nn,2,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax[0,0].set_xlim((-150,150))\n",
    "ax[0,0].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh1, pad=0.15, label='Photon number')\n",
    "ax[0,1].set_xlim((-150,150))\n",
    "ax[0,1].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh2, pad=0.15, label='Photon number')\n",
    "ax[1,0].set_xlim((-150,150))\n",
    "ax[1,0].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh3, pad=0.15, label='Photon number')\n",
    "ax[1,1].set_xlim((-150,150))\n",
    "ax[1,1].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh4, pad=0.15, label='Photon number')\n",
    "ax[0,2].set_xlim((-150,150))\n",
    "ax[0,2].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh5, pad=0.15, label='Photon number')\n",
    "ax[1,2].set_xlim((-150,150))\n",
    "ax[1,2].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh6, pad=0.15, label='Photon number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal(psf):\n",
    "    return torch.mean(torch.max(torch.flatten(psf, start_dim=1), dim=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_pos(xp, yp, zp, rho, eta, delta, N_photons, data, second_plane, background, sigma, dim_simu):\n",
    "    u, v, M_ = compute_M(xp=xp, yp=yp, zp=zp, d=d_, x=xx, y=yy, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k_, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections, N=N,\n",
    "                    l_pixel=l_pixel, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG, device=device, aberrations=False)\n",
    "    dim_data = 6\n",
    "    h = PSF(rho=rho, eta=eta, delta=delta, M=M_, N_photons=N_photons)[:,:,:,dim_simu-dim_data:dim_simu+dim_data+1,dim_simu-dim_data:dim_simu+dim_data+1]\n",
    "    loss = torch.sum(torch.add(h, -(data+sigma**2)*torch.log(h+background+sigma**2)))\n",
    "    #loss = torch.sum(torch.pow(torch.sum(torch.add(h, -data), dim=(2,)), 2)) \n",
    "    x_bound = limit(xp, 5*0.12, 100, upper=True) + limit(xp, -5*0.12, 100, upper=False)\n",
    "    y_bound = limit(yp, 5*0.12, 100, upper=True) + limit(yp, -5*0.12, 100, upper=False)\n",
    "    z_bound = limit(zp, 5., 100, upper=True) + limit(zp, 0, 100, upper=False)\n",
    "    N_bound = limit(N_photons, 10000., 0.01, upper=True)\n",
    "    return loss +x_bound+y_bound+z_bound#+N_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_N(xp, yp, zp, rho, eta, delta, N_photons, data, second_plane, background, sigma, dim_simu):\n",
    "    u, v, M_ = compute_M(xp=xp, yp=yp, zp=zp, d=d_, x=xx, y=yy, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k_, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections, N=N,\n",
    "                    l_pixel=l_pixel, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG, device=device, aberrations=False)\n",
    "    dim_data = 6\n",
    "    h = PSF(rho=rho, eta=eta, delta=delta, M=M_, N_photons=N_photons)[:,:,:,dim_simu-dim_data:dim_simu+dim_data+1,dim_simu-dim_data:dim_simu+dim_data+1]\n",
    "    #loss = torch.sum(torch.add(h, -(data+sigma**2)*torch.log(h+background+sigma**2)))\n",
    "    loss = torch.sum(torch.sqrt(torch.pow(torch.sum(torch.add(h, -data), dim=(2,)), 2))) \n",
    "    x_bound = limit(xp, 5*0.12, 100, upper=True) + limit(xp, -5*0.12, 100, upper=False)\n",
    "    y_bound = limit(yp, 5*0.12, 100, upper=True) + limit(yp, -5*0.12, 100, upper=False)\n",
    "    z_bound = limit(zp, 5., 100, upper=True) + limit(zp, 0, 100, upper=False)\n",
    "    N_bound = limit(N_photons, 10000., 0.01, upper=True)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = 11.\n",
    "sig_b = 6.\n",
    "read=1.5\n",
    "bias=11.\n",
    "psf_n = noise(psf, QE=1, EM=1, b=background, sigma_b=sig_b, sigma_r=read, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_simu = int(psf_n.shape[-1]//2)\n",
    "dim_data = 6\n",
    "psf_n = psf_n[:,:,:,dim_simu-dim_data:dim_simu+dim_data+1,dim_simu-dim_data:dim_simu+dim_data+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('z = ', z[nn].cpu().detach().numpy())\n",
    "\n",
    "vmax=torch.max(psf_n[nn]).cpu().detach().numpy()\n",
    "vmin=torch.min(psf_n[nn]).cpu().detach().numpy()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15,9]\n",
    "fig, ax = plt.subplots(2,3)\n",
    "mesh1 = ax[0,0].pcolormesh(psf_n[nn,0,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh2 = ax[1,0].pcolormesh(psf_n[nn,0,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh3 = ax[0,1].pcolormesh(psf_n[nn,1,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh4 = ax[1,1].pcolormesh(psf_n[nn,1,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh5 = ax[0,2].pcolormesh(psf_n[nn,2,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh6 = ax[1,2].pcolormesh(psf_n[nn,2,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "cb = plt.colorbar(mesh1, pad=0.15, label='Photon number')\n",
    "cb = plt.colorbar(mesh2, pad=0.15, label='Photon number')\n",
    "cb = plt.colorbar(mesh3, pad=0.15, label='Photon number')\n",
    "cb = plt.colorbar(mesh4, pad=0.15, label='Photon number')\n",
    "cb = plt.colorbar(mesh5, pad=0.15, label='Photon number')\n",
    "cb = plt.colorbar(mesh6, pad=0.15, label='Photon number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v, M = compute_M(xp=xp, yp=yp, zp=z, d=d_, x=x, y=y, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k_, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections, N=N, l_pixel=l_pixel, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG,\n",
    "                   device=device, aberrations=False, defocus_coef=1e-5, spherical_coef=-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy, th1, phi, [Ex0, Ex1, Ex2], [Ey0, Ey1, Ey2], r, r_cut, k_, f_o = vectorial_BFP_perfect_focus(N, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_p_list = np.linspace(800, 8000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Np in N_p_list:\n",
    "    psf = PSF(rho=rho, eta=eta, delta=delta, M=M, N_photons=Np)\n",
    "    psf_n = noise(psf, QE=1, EM=1, b=background, sigma_b=sig_b, sigma_r=read, bias=bias)\n",
    "    psf_n = psf_n[:,:,:,dim_simu-dim_data:dim_simu+dim_data+1,dim_simu-dim_data:dim_simu+dim_data+1]\n",
    "\n",
    "    B = background + bias\n",
    "    sig_r = np.sqrt(read**2 + sig_b**2)\n",
    "    N_start = torch.tensor([3000 for i in range(100)], requires_grad=False, device=device)\n",
    "    x_start = torch.tensor([0. for i in range(100)], requires_grad=False, device=device)\n",
    "    y_start = torch.tensor([0. for i in range(100)], requires_grad=False, device=device)\n",
    "    z_start =  z + torch.tensor(np.random.rand(100)-0.5, requires_grad=False, device=device)\n",
    "\n",
    "    rho_ = rho + torch.tensor(20*(2*np.random.rand(100)-1), requires_grad=False, device=device)\n",
    "    delta_ = delta + torch.tensor(20*(2*np.random.rand(100)-1), requires_grad=False, device=device)\n",
    "    eta_ = torch.tensor([45. for i in range(100)], requires_grad=False, device=device)\n",
    "\n",
    "    params = torch.cat((x_start, y_start, z_start, N_start/1000))\n",
    "    params.requires_grad=True\n",
    "\n",
    "    # Use Stochastic Gradient Descent (SGD) to optimize params\n",
    "    optimizer = torch.optim.Adam([params], lr=0.1)  # Learning rate = 0.01\n",
    "\n",
    "    num_epochs_max = 100\n",
    "    loss_ = []\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    z_ = []\n",
    "    N_ = []\n",
    "\n",
    "    for i in tqdm(range(num_epochs_max)):\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        loss = loss_pos(params[0:100], params[100:200], params[200:300], rho_, eta_, delta_, params[300:]*1000, psf_n.detach(), second_plane, B, sig_r, dim_simu)\n",
    "        loss_.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        x_.append(params[:100].cpu().detach().numpy())\n",
    "        y_.append(params[100:200].cpu().detach().numpy())\n",
    "        z_.append(params[200:300].cpu().detach().numpy())\n",
    "        N_.append(params[300:400].cpu().detach().numpy()*1000)\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update parameters\n",
    "\n",
    "    signal_ = signal(psf.cpu().detach())\n",
    "    np.savez_compressed('D:/AMAURY\\data_simu/stage/2025_07_25_xy_loc_precision/'+str(Np)+'.npz', signal=signal_.detach().numpy(), std=sig_r, floor=B, x=np.array(x_-xp.cpu().clone().detach().numpy())[-1,:], y=np.array(y_-yp.cpu().clone().detach().numpy())[-1,:], z=np.array(z_-z.cpu().clone().detach().numpy())[-1,:], Nphotons_retreived=np.array(N_)[-1,:], Nphotons_retreived2=np.array(N_2)[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/AMAURY/data_simu/stage/2025_07_25_xy_loc_precision'\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "N = []\n",
    "floors = []\n",
    "stds = []\n",
    "signals = []\n",
    "for file in os.listdir(folder):\n",
    "    if float(file[:-4]) in N_p_list:\n",
    "        data = np.load(folder+'/'+file)\n",
    "        x.append(data['x'])\n",
    "        y.append(data['y'])\n",
    "        z.append(data['z'])\n",
    "        N.append(data['Nphotons_retreived'])\n",
    "        stds.append(data['std'])\n",
    "        signals.append(data['signal'])\n",
    "        floors.append(data['floor'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "z = np.array(z)\n",
    "stds = np.array(stds)\n",
    "N = np.array(N)\n",
    "signals = np.array(signals)\n",
    "floors = np.array(floors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kjhj= plt.hist(x.flatten(), bins=1000)\n",
    "#plt.xlim((-0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (x**2>0.2**2) \n",
    "x[mask] = np.nan\n",
    "mask = (y**2>0.2**2) \n",
    "y[mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kjhj= plt.hist(z.flatten(), bins=1000)\n",
    "#plt.xlim((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (z**2>1.2**2) \n",
    "z[mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['figure.figsize'] = [3,2]\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "ax.scatter(N_p_list, 1000*np.nanmean(x,axis=1), c='r', label='x localization', s=8)\n",
    "ax.scatter(N_p_list, 1000*np.nanmean(y,axis=1), c='b', label='y localization', s=8)\n",
    "ax.grid()\n",
    "ax.set_xlim((800,7000))\n",
    "ax.set_ylim((-10,10))\n",
    "ax.set_xlabel('$ N_{\\\\mathrm{PHOTONS}}$')\n",
    "ax.set_ylabel('Mean error (nm)')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(N_p_list, 1000*np.nanmean(z,axis=1), c='g', s=8)\n",
    "ax.grid()\n",
    "ax.set_xlim((800,7000))\n",
    "ax.set_ylim((-100,100))\n",
    "ax.set_xlabel('$ N_{\\\\mathrm{PHOTONS}}$')\n",
    "ax.set_ylabel('Mean error (nm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 10})\n",
    "plt.rcParams['figure.figsize'] = [18,3.]\n",
    "fig, ax = plt.subplots(1,3)\n",
    "\n",
    "#ax[0].scatter(N_p_list, 1000*(np.percentile(x, 75, axis=1)-np.percentile(x, 25, axis=1)), c='r', label='x localization', s=8)\n",
    "#ax[0].scatter(N_p_list, 1000*(np.percentile(y, 75, axis=1)-np.percentile(y, 25, axis=1)), c='b', label='y localization', s=8)\n",
    "ax[0].scatter(N_p_list, 1000*np.nanstd(x,axis=1), c='r', label='x localization', s=8)\n",
    "ax[0].scatter(N_p_list, 1000*np.nanstd(y,axis=1), c='b', label='y localization', s=8)\n",
    "'''for iter in range(x.shape[0]):\n",
    "    ax[0].scatter([N_p_list[iter] for i in range(x.shape[1])], 1000*x[iter], c='r', s=2)\n",
    "ax[0].fill_between(N_p_list, np.mean(1000*x, axis=1)-np.std(1000*x, axis=1)/2, np.mean(1000*x, axis=1)+np.std(1000*x, axis=1)/2, color='r', alpha=0.3)\n",
    "for iter in range(z.shape[0]):\n",
    "    ax[0].scatter([N_p_list[iter] for i in range(y.shape[1])], 1000*y[iter], c='r', s=2)\n",
    "ax[0].fill_between(N_p_list, np.mean(1000*y, axis=1)-np.std(1000*y, axis=1)/2, np.mean(1000*y, axis=1)+np.std(1000*y, axis=1)/2, color='b', alpha=0.3)'''\n",
    "ax[0].legend(loc='lower left')\n",
    "ax[0].grid()\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xlim((800,7000))\n",
    "ax[0].set_ylim((4,200))\n",
    "ax[0].set_xlabel('$ N_{\\\\mathrm{PHOTONS}}$')\n",
    "ax[0].set_ylabel('$ \\sigma_{\\\\mathrm{lat}}$ (nm)')\n",
    "\n",
    "\n",
    "'''for iter in range(z.shape[0]):\n",
    "    ax[1].scatter([N_p_list[iter] for i in range(z.shape[1])], 1000*z[iter], c='r', s=2)\n",
    "ax[1].fill_between(N_p_list, np.mean(1000*z, axis=1)-np.std(1000*z, axis=1)/2, np.mean(1000*z, axis=1)+np.std(1000*z, axis=1)/2, color='r', alpha=0.3)'''\n",
    "ax[1].scatter(N_p_list, 1000*np.std(z,axis=1), c='g', s=8)\n",
    "ax[1].grid()\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xlim((800,7000))\n",
    "ax[1].set_xlabel('$ N_{\\\\mathrm{PHOTONS}}$')\n",
    "ax[1].set_ylabel('$ \\sigma_{\\\\mathrm{z}}$ (nm)')\n",
    "\n",
    "for iter in range(N.shape[0]):\n",
    "    ax[2].scatter([N_p_list[iter] for i in range(N.shape[1])], N[iter], c='r', s=2)\n",
    "ax[2].fill_between(N_p_list, np.mean(N, axis=1)-np.std(N, axis=1)/2, np.mean(N, axis=1)+np.std(N, axis=1)/2, color='y', alpha=0.8)\n",
    "ax[2].plot(N_p_list, N_p_list)\n",
    "ax[2].grid()\n",
    "ax[2].set_xlim((800,7000))\n",
    "ax[2].set_xlabel('$ N_{\\\\mathrm{PHOTONS}}$')\n",
    "ax[2].set_ylabel('$ N_{\\\\mathrm{RETRIEVED}}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
