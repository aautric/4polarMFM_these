{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simu_PSF_polar import *\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [5,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using GPU\")\n",
    "else:   \n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit(x, lim, slope, upper=True):\n",
    "    '''\n",
    "    if upper:\n",
    "       return torch.sum(torch.tensor(1/(1+torch.exp(-slope*(x-lim))), requires_grad=True, device=device))\n",
    "    else:\n",
    "        return torch.sum(torch.tensor(1/(1+torch.exp(slope*(x-lim))), requires_grad=True, device=device))\n",
    "    '''\n",
    "    if upper:\n",
    "        return torch.sum(torch.exp((x-lim)*slope))\n",
    "    else:\n",
    "        return torch.sum(torch.exp(-1*(x-lim)*slope))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_photons= torch.tensor(5000., device=device)\n",
    "N=torch.tensor(80, device=device)\n",
    "l_pixel=torch.tensor(16, device=device)\n",
    "NA=torch.tensor(1.4, device=device)\n",
    "mag=torch.tensor(100, device=device)\n",
    "lambd=torch.tensor(617, device=device)\n",
    "f_tube=torch.tensor(200, device=device)\n",
    "MAG=torch.tensor(200/150, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = torch.tensor([0. for k in range(100)], device=device)\n",
    "yp = torch.tensor([0. for k in range(100)], device=device)\n",
    "z = torch.tensor((1.+np.random.rand(100))*0.8, device=device) #position of dipole in lambda units\n",
    "d_ = torch.tensor([-1.5 for k in range(100)], device=device) #defocus of dipole in lambda units 4.4\n",
    "rho = torch.tensor(10.+160.*np.random.rand(100), requires_grad=True, device=device)\n",
    "eta = torch.tensor([50. for k in range(100)], requires_grad=True, device=device)# 70\n",
    "delta = torch.tensor([80. for k in range(100)], requires_grad=True, device=device)#50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, th1, phi, [Ex0, Ex1, Ex2], [Ey0, Ey1, Ey2], r, r_cut, k, f_o = vectorial_BFP_perfect_focus(N, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_plane = torch.tensor([0.35, 0, -0.35], device=device)\n",
    "polar_projections = torch.tensor([0., 45., 0.], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v, M = compute_M(xp=xp, yp=yp, zp=z, d=d_, x=x, y=y, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k, f_o=f_o, second_plane=second_plane, polar_projections=polar_projections, N=N, l_pixel=l_pixel, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG,\n",
    "                   device=device, aberrations=False, defocus_coef=1e-5, spherical_coef=-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = PSF(rho=rho, eta=eta, delta=delta, M=M, N_photons=N_photons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 12\n",
    "print('z = ', z[nn].cpu().detach().numpy())\n",
    "\n",
    "vmax=torch.max(psf[nn]).cpu().detach().numpy()\n",
    "vmin=torch.min(psf[nn]).cpu().detach().numpy()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15,9]\n",
    "fig, ax = plt.subplots(2,3)\n",
    "mesh1 = ax[0,0].pcolormesh(u.cpu(), v.cpu(), psf[nn,0,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh2 = ax[1,0].pcolormesh(u.cpu(), v.cpu(), psf[nn,0,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh3 = ax[0,1].pcolormesh(u.cpu(), v.cpu(), psf[nn,1,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh4 = ax[1,1].pcolormesh(u.cpu(), v.cpu(), psf[nn,1,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh5 = ax[0,2].pcolormesh(u.cpu(), v.cpu(), psf[nn,2,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh6 = ax[1,2].pcolormesh(u.cpu(), v.cpu(), psf[nn,2,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax[0,0].set_xlim((-150,150))\n",
    "ax[0,0].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh1, pad=0.15, label='Photon number')\n",
    "ax[0,1].set_xlim((-150,150))\n",
    "ax[0,1].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh2, pad=0.15, label='Photon number')\n",
    "ax[1,0].set_xlim((-150,150))\n",
    "ax[1,0].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh3, pad=0.15, label='Photon number')\n",
    "ax[1,1].set_xlim((-150,150))\n",
    "ax[1,1].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh4, pad=0.15, label='Photon number')\n",
    "ax[0,2].set_xlim((-150,150))\n",
    "ax[0,2].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh5, pad=0.15, label='Photon number')\n",
    "ax[1,2].set_xlim((-150,150))\n",
    "ax[1,2].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh6, pad=0.15, label='Photon number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal(psf):\n",
    "    return torch.mean(torch.max(torch.flatten(psf, start_dim=1), dim=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_loss(M, rho, eta, delta, N_photons, data):\n",
    "    h = PSF(rho=rho, eta=eta, delta=delta, M=M, N_photons=N_photons)\n",
    "    #\n",
    "    # loss = torch.sum(torch.add(h, -data).pow(2))\n",
    "    loss = torch.sum(torch.add(h, -(data+sig_r**2)*torch.log(h+B+sig_r**2)))\n",
    "    #rho_bound = limit(rho, 180, 100, upper=True) + limit(rho, 0, 100, upper=False)\n",
    "    delta_bound = limit(delta, 180, 100, upper=True) + limit(delta, 1, 100, upper=False)\n",
    "    #eta_bound = limit(eta, 180, 100, upper=True) + limit(eta, 0, 100, upper=False)\n",
    "    return loss + 1000.*(delta_bound) #+ 0.1*torch.sum(h.pow(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = 11.\n",
    "sig_b = 6.\n",
    "read=1.5\n",
    "bias=11.\n",
    "psf_n = noise(psf, QE=1, EM=1, b=background, sigma_b=sig_b, sigma_r=read, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('z = ', z[nn].cpu().detach().numpy())\n",
    "\n",
    "vmax=torch.max(psf_n[nn]).cpu().detach().numpy()\n",
    "vmin=torch.min(psf_n[nn]).cpu().detach().numpy()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15,9]\n",
    "fig, ax = plt.subplots(2,3)\n",
    "mesh1 = ax[0,0].pcolormesh(u.cpu(), v.cpu(), psf_n[nn,0,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh2 = ax[1,0].pcolormesh(u.cpu(), v.cpu(), psf_n[nn,0,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh3 = ax[0,1].pcolormesh(u.cpu(), v.cpu(), psf_n[nn,1,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh4 = ax[1,1].pcolormesh(u.cpu(), v.cpu(), psf_n[nn,1,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh5 = ax[0,2].pcolormesh(u.cpu(), v.cpu(), psf_n[nn,2,0].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "mesh6 = ax[1,2].pcolormesh(u.cpu(), v.cpu(), psf_n[nn,2,1].cpu().detach().numpy(), cmap='gray', vmin=vmin, vmax=vmax)\n",
    "ax[0,0].set_xlim((-150,150))\n",
    "ax[0,0].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh1, pad=0.15, label='Photon number')\n",
    "ax[0,1].set_xlim((-150,150))\n",
    "ax[0,1].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh2, pad=0.15, label='Photon number')\n",
    "ax[1,0].set_xlim((-150,150))\n",
    "ax[1,0].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh3, pad=0.15, label='Photon number')\n",
    "ax[1,1].set_xlim((-150,150))\n",
    "ax[1,1].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh4, pad=0.15, label='Photon number')\n",
    "ax[0,2].set_xlim((-150,150))\n",
    "ax[0,2].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh5, pad=0.15, label='Photon number')\n",
    "ax[1,2].set_xlim((-150,150))\n",
    "ax[1,2].set_ylim((-150,150))\n",
    "cb = plt.colorbar(mesh6, pad=0.15, label='Photon number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = background + bias\n",
    "sig_r = np.sqrt(read**2 + sig_b**2)\n",
    "''' \n",
    "xp_error = (xp.cpu().clone().detach() + 0.02*(np.random.rand(100)-0.5)).to(device)\n",
    "yp_error = (yp.cpu().clone().detach() + 0.02*(np.random.rand(100)-0.5)).to(device)\n",
    "z_error = (z.cpu().clone().detach() + 0.04*(np.random.rand(100)-0.5)).to(device)\n",
    "\n",
    "u, v, M = compute_M(xp=xp_error, yp=yp_error, zp=z_error, d=d_, x=x, y=y, th1=th1, phi=phi, Ex0=Ex0, Ex1=Ex1, Ex2=Ex2\n",
    "                    , Ey0=Ey0, Ey1=Ey1, Ey2=Ey2, r=r, r_cut=r_cut, k=k, f_o=f_o, second_plane=0.4, N=N, l_pixel=l_pixel, NA=NA, mag=mag, lambd=lambd, f_tube=f_tube, MAG=MAG, device=device)\n",
    "'''\n",
    "#DELTA = (delta.cpu().clone().detach()+40.*(np.random.rand(100)-0.5)).to(device=device)\n",
    "\n",
    "params = torch.tensor(np.concatenate((rho.cpu().clone().detach()+130.*(np.random.rand(100)-0.5), #rho\n",
    "                                     np.array([90. for i in range(100)]), #eta\n",
    "                                     delta.cpu().clone().detach()+80.*(np.random.rand(100)-0.5))),\n",
    "                                     requires_grad=True, device=device)\n",
    "params_prev = params.clone().detach() - torch.tensor([2. for k in range(len(params))], device=device)\n",
    "'''\n",
    "thresh_rho = 10.\n",
    "thresh_delta = 10.\n",
    "rho_guess = params[0:100].clone().detach()\n",
    "delta_guess = params[200:300].clone().detach()\n",
    "\n",
    "lambd = 1.\n",
    "'''\n",
    "\n",
    "# Use Stochastic Gradient Descent (SGD) to optimize params\n",
    "optimizer = torch.optim.Adam([params], lr=0.9)  # Learning rate = 0.01\n",
    "\n",
    "num_epochs_max = 250\n",
    "loss_ = []\n",
    "rho_ = []\n",
    "eta_ = []\n",
    "delta_ = []\n",
    "N_p = []\n",
    "\n",
    "tour=0\n",
    "\n",
    "#for u in range(5000):\n",
    "for it in range(num_epochs_max):\n",
    "    params_prev = params.clone().detach()\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    #print(params[0:3], params[3:6], params[6:])\n",
    "    loss = general_loss(M.detach(), params[0:100], params[100:200], params[200:], N_photons.detach(), psf_n.detach())\n",
    "    #loss = general_loss(M.detach(), params[0], params[1], params[2], N_photons.detach(), psf.detach())\n",
    "    loss_.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    rho___ = params[0:100].cpu().clone().detach().numpy()%180\n",
    "    rho___[rho___-rho.cpu().clone().detach().numpy() > 90] = rho___[rho___-rho.cpu().clone().detach().numpy() > 90] - 180.\n",
    "    rho___[rho___-rho.cpu().clone().detach().numpy() < -90] = rho___[rho___-rho.cpu().clone().detach().numpy() < -90] + 180.\n",
    "    eta___ = params[100:200].cpu().clone().detach().numpy()%180\n",
    "    eta___[eta___-eta.cpu().clone().detach().numpy() > 90] = eta___[eta___-eta.cpu().clone().detach().numpy() > 90] - 180.\n",
    "    eta___[eta___-eta.cpu().clone().detach().numpy() < -90] = eta___[eta___-eta.cpu().clone().detach().numpy() < -90] + 180.\n",
    "    rho_.append(rho___)\n",
    "    eta_.append(eta___)\n",
    "    delta_.append(params[200:].cpu().clone().detach().numpy())\n",
    "\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update parameters\n",
    "    tour+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ = signal(psf.cpu().detach())\n",
    "print(signal_/sig_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [25,3.5]\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots(1,4)\n",
    "ax[0].plot(loss_)    \n",
    "ax[0].set_xlabel('Iteration')\n",
    "ax[0].set_ylabel('Loss', labelpad=0.1)\n",
    "#ax[0].set_ylim((np.min(loss_), np.max(loss_)))\n",
    "ax[0].grid()\n",
    "ax[1].plot(np.array(rho_)-rho.cpu().clone().detach().numpy())\n",
    "ax[1].set_xlabel('Iteration')\n",
    "ax[1].set_ylabel('$\\\\Delta \\\\rho$ ($\\\\degree$)', labelpad=0.01)\n",
    "ax[1].set_title('std = '+str(int(1000*np.nanstd((np.array(rho_)-rho.cpu().clone().detach().numpy())[:][-1]))/1000)+'\\n mean = '+str(int(1000*np.nanmean((np.array(rho_)-rho.cpu().clone().detach().numpy())[:][-1]))/1000))\n",
    "ax[1].grid()\n",
    "ax[2].plot(eta_)\n",
    "ax[2].axhline(eta[0].cpu().detach().numpy(), c='r', label='Ground truth')\n",
    "ax[2].legend()\n",
    "ax[2].set_xlabel('Iteration')\n",
    "ax[2].set_ylabel('$\\\\eta$ ($\\\\degree$)', labelpad=0.1)\n",
    "ax[2].set_title('std = '+str(int(1000*np.nanstd(eta_[:][-1]))/1000)+'\\n mean = '+str(int(1000*np.nanmean(eta_[:][-1]))/1000))\n",
    "ax[2].grid()\n",
    "ax[3].plot(delta_)\n",
    "ax[3].axhline(delta[0].cpu().detach().numpy(), c='r', label='Ground truth')\n",
    "ax[3].legend()\n",
    "ax[3].set_xlabel('Iteration')\n",
    "ax[3].set_ylabel('$\\\\delta$ ($\\\\degree$)', labelpad=0.1)\n",
    "ax[3].set_title('std = '+str(int(1000*np.nanstd(delta_[:][-1]))/1000)+'\\n mean = '+str(int(1000*np.nanmean(delta_[:][-1]))/1000))\n",
    "ax[3].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('D:/AMAURY/data_simu/stage/2025_07_10_SNR_20_70/1000_photons.npz', signal=signal_.detach().numpy(), std=sig_r, floor=B, rho=np.array(rho_-rho.cpu().clone().detach().numpy())[-1,:], eta=np.array(eta_)[-1,:], delta=np.array(delta_)[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/AMAURY/data_simu/stage/2025_07_10_SNR_70_120'\n",
    "rhos = []\n",
    "etas = []\n",
    "deltas = []\n",
    "floors = []\n",
    "stds = []\n",
    "signals = []\n",
    "Nphotons = [1000, 1500, 2000, 3000, 4000, 5000]\n",
    "for file in ['1000_photons', '1500_photons', '2000_photons', '3000_photons', '4000_photons', '5000_photons']:\n",
    "    data = np.load(folder+'/'+file+'.npz')\n",
    "    rhos.append(data['rho'])\n",
    "    etas.append(data['eta'])\n",
    "    deltas.append(data['delta'])\n",
    "    stds.append(data['std'])\n",
    "    signals.append(data['signal'])\n",
    "    floors.append(data['floor'])\n",
    "\n",
    "eta_true = 70.\n",
    "delta_true = 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/AMAURY/data_simu/stage/2025_07_10_SNR_45_120'\n",
    "rhos = []\n",
    "etas = []\n",
    "deltas = []\n",
    "floors = []\n",
    "stds = []\n",
    "signals = []\n",
    "Nphotons = [1000, 1500, 2000, 3000, 4000, 5000]\n",
    "for file in ['1000_photons', '1500_photons', '2000_photons', '3000_photons', '4000_photons', '5000_photons']:\n",
    "    data = np.load(folder+'/'+file+'.npz')\n",
    "    rhos.append(data['rho'])\n",
    "    etas.append(data['eta'])\n",
    "    deltas.append(data['delta'])\n",
    "    stds.append(data['std'])\n",
    "    signals.append(data['signal'])\n",
    "    floors.append(data['floor'])\n",
    "\n",
    "eta_true = 45.\n",
    "delta_true = 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/AMAURY/data_simu/stage/2025_07_10_SNR_20_120'\n",
    "rhos = []\n",
    "etas = []\n",
    "deltas = []\n",
    "floors = []\n",
    "stds = []\n",
    "signals = []\n",
    "Nphotons = [1000, 1500, 2000, 3000, 4000, 5000]\n",
    "for file in ['1000_photons', '1500_photons', '2000_photons', '3000_photons', '4000_photons', '5000_photons']:\n",
    "    data = np.load(folder+'/'+file+'.npz')\n",
    "    rhos.append(data['rho'])\n",
    "    etas.append(data['eta'])\n",
    "    deltas.append(data['delta'])\n",
    "    stds.append(data['std'])\n",
    "    signals.append(data['signal'])\n",
    "    floors.append(data['floor'])\n",
    "\n",
    "eta_true = 20.\n",
    "delta_true = 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/AMAURY/data_simu/stage/2025_07_10_SNR_70_70'\n",
    "rhos = []\n",
    "etas = []\n",
    "deltas = []\n",
    "floors = []\n",
    "stds = []\n",
    "signals = []\n",
    "Nphotons = [1000, 1500, 2000, 3000, 4000, 5000]\n",
    "for file in ['1000_photons', '1500_photons', '2000_photons', '3000_photons', '4000_photons', '5000_photons']:\n",
    "    data = np.load(folder+'/'+file+'.npz')\n",
    "    rhos.append(data['rho'])\n",
    "    etas.append(data['eta'])\n",
    "    deltas.append(data['delta'])\n",
    "    stds.append(data['std'])\n",
    "    signals.append(data['signal'])\n",
    "    floors.append(data['floor'])\n",
    "\n",
    "eta_true = 70.\n",
    "delta_true = 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/AMAURY/data_simu/stage/2025_07_10_SNR_45_70'\n",
    "rhos = []\n",
    "etas = []\n",
    "deltas = []\n",
    "floors = []\n",
    "stds = []\n",
    "signals = []\n",
    "Nphotons = [1000, 1500, 2000, 3000, 4000, 5000]\n",
    "for file in ['1000_photons', '1500_photons', '2000_photons', '3000_photons', '4000_photons', '5000_photons']:\n",
    "    data = np.load(folder+'/'+file+'.npz')\n",
    "    rhos.append(data['rho'])\n",
    "    etas.append(data['eta'])\n",
    "    deltas.append(data['delta'])\n",
    "    stds.append(data['std'])\n",
    "    signals.append(data['signal'])\n",
    "    floors.append(data['floor'])\n",
    "\n",
    "eta_true = 45.\n",
    "delta_true = 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/AMAURY/data_simu/stage/2025_07_10_SNR_20_70'\n",
    "rhos = []\n",
    "etas = []\n",
    "deltas = []\n",
    "floors = []\n",
    "stds = []\n",
    "signals = []\n",
    "Nphotons = [1000, 1500, 2000, 3000, 4000, 5000]\n",
    "for file in ['1000_photons', '1500_photons', '2000_photons', '3000_photons', '4000_photons', '5000_photons']:\n",
    "    data = np.load(folder+'/'+file+'.npz')\n",
    "    rhos.append(data['rho'])\n",
    "    etas.append(data['eta'])\n",
    "    deltas.append(data['delta'])\n",
    "    stds.append(data['std'])\n",
    "    signals.append(data['signal'])\n",
    "    floors.append(data['floor'])\n",
    "\n",
    "eta_true = 20.\n",
    "delta_true = 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [17,3.5]\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "fig, ax = plt.subplots(1,3)\n",
    "\n",
    "ax[0].violinplot(rhos, positions=np.array(Nphotons)/1000, showextrema=True, showmedians=True, widths=0.5)\n",
    "ax[0].grid()\n",
    "ax[0].set_xticks(np.array(Nphotons)/1000)\n",
    "ax[0].set_xticklabels((np.array(Nphotons)/1000).astype(str))\n",
    "ax02 = ax[0].twiny()\n",
    "ax02.set_xlim(ax[0].get_xlim())\n",
    "ax02.set_xticks(np.array(Nphotons)/1000)\n",
    "ax02.set_xticklabels((np.array(signals)/np.array(stds)).astype(int).astype(str))\n",
    "ax02.set_xlabel('SNR')\n",
    "ax[0].set_ylabel('$\\\\Delta \\\\rho$ ($^{\\\\circ}$)')\n",
    "ax[0].set_xlabel('Number of photon ($\\\\times$1000)')\n",
    "ax[0].set_ylim((-90,90))\n",
    "\n",
    "ax[1].violinplot(etas, positions=np.array(Nphotons)/1000, showextrema=True, showmedians=True, widths=0.5)\n",
    "ax[1].grid()\n",
    "ax[1].axhline(eta_true, c='r', label='ground truth')\n",
    "ax[1].set_xticks(np.array(Nphotons)/1000)\n",
    "ax[1].set_xticklabels((np.array(Nphotons)/1000).astype(str))\n",
    "ax12 = ax[1].twiny()\n",
    "ax12.set_xlim(ax[1].get_xlim())\n",
    "ax12.set_xticks(np.array(Nphotons)/1000)\n",
    "ax12.set_xticklabels((np.array(signals)/np.array(stds)).astype(int).astype(str))\n",
    "ax12.set_xlabel('SNR')\n",
    "ax[1].set_ylabel('$\\\\eta$ ($^{\\\\circ}$)')\n",
    "ax[1].set_xlabel('Number of photon ($\\\\times$1000)')\n",
    "ax[1].legend()\n",
    "ax[1].set_ylim((0,180))\n",
    "\n",
    "ax[2].violinplot(deltas, positions=np.array(Nphotons)/1000, showextrema=True, showmedians=True, widths=0.5)\n",
    "ax[2].grid()\n",
    "ax[2].axhline(delta_true, c='r', label='ground truth')\n",
    "ax[2].set_xticks(np.array(Nphotons)/1000)\n",
    "ax[2].set_xticklabels((np.array(Nphotons)/1000).astype(str))\n",
    "ax22 = ax[2].twiny()\n",
    "ax22.set_xlim(ax[2].get_xlim())\n",
    "ax22.set_xticks(np.array(Nphotons)/1000)\n",
    "ax22.set_xticklabels((np.array(signals)/np.array(stds)).astype(int).astype(str))\n",
    "ax22.set_xlabel('SNR')\n",
    "ax[2].set_ylabel('$\\\\delta$ ($^{\\\\circ}$)')\n",
    "ax[2].set_xlabel('Number of photon ($\\\\times$1000)')\n",
    "ax[2].legend()\n",
    "ax[2].set_ylim((0,180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
